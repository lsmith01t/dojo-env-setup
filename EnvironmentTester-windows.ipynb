{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "884ad119",
   "metadata": {},
   "source": [
    "# Environment Tester"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f3bcbe",
   "metadata": {},
   "source": [
    "- The following notebook is meant to be a quick summary/verification of your computers environment.\n",
    "- Please run all of the cells to get all of the information displayed. \n",
    "    - Either Press `Shift + Enter` to run each cell \n",
    "    - OR Click on `Kernel`> `Restart & Run All`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6aeb364",
   "metadata": {},
   "source": [
    "## Conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cac8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Exporting Troubleshooting report\n",
    "%run \"Troubleshooting/Troubleshooting Report.ipynb\"\n",
    "\n",
    "# with open(\"FINAL_REPORT.txt\") as f:\n",
    "# \tfinal_report = f.read()\n",
    "# # print(final_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c407030",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Recording time notebook was run\n",
    "import datetime as dt\n",
    "from tzlocal import get_localzone, get_localzone_name\n",
    "now = dt.datetime.now(get_localzone())\n",
    "now_nice = now.strftime(\"%m/%d/%Y @ %I:%M:%S %p \") + f\"(tz={get_localzone_name().split('/')[-1]})\"\n",
    "print(f'[i] Environment Tester Notebook started at: {now_nice}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fedf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GET CURRENT ENVIRONMENT INFO\n",
    "%conda info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83a69c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CHECK PYTHON VERSION (should be 3.8.13)\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508c0333",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Folder path to python\n",
    "!which python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e024806d",
   "metadata": {},
   "source": [
    "## Python Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe05fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.4.2\n",
    "import pandas as pd\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9948193a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.22.4\n",
    "import numpy as np\n",
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dd7f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.4.3\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181a1dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.11.2\n",
    "import seaborn as sns\n",
    "sns.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa602f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1.1\n",
    "import sklearn as sk\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sk.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203919a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.8.1\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "sp.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bc3802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.0.2\n",
    "import pymysql\n",
    "pymysql.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abb33c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.13.2\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "statsmodels.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a94f9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.8.5\n",
    "import pmdarima as pmd\n",
    "pmd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e4025b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.41.0\n",
    "import shap\n",
    "shap.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566ba727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.9.1\n",
    "import imblearn\n",
    "imblearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae01bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.6.7\n",
    "import dython \n",
    "dython.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbc20ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.2.7\n",
    "import interpret\n",
    "interpret.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003549e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## As long as m1 mac installed the m1 env, this should work\n",
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79a3309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1.1\n",
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fa70a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.10.0\n",
    "import sktime \n",
    "sktime.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb75ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.0\n",
    "import prophet\n",
    "prophet.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8210efbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pystan\n",
    "pystan.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13c174c",
   "metadata": {},
   "source": [
    "## Jupyter Notebook Extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b23bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install jupyter_contrib_nbextensions\n",
    "!jupyter contrib nbextension install --user\n",
    "!jupyter nbextension enable jupyter_nbextensions_configurator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e89862",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbextension enable toc2/main\n",
    "!jupyter nbextension enable collapsible_headings/main\n",
    "!jupyter nbextension enable ruler/main\n",
    "!jupyter nbextension enable livemdpreview/livemdpreview \n",
    "!jupyter nbextension enable spellchecker/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2f5313",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CHeck if nbextensions installed\n",
    "!jupyter nbextension list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67398f8b",
   "metadata": {},
   "source": [
    ">- **Note: if you see any warning messages about `x: problems found`**, but your notebook continued to run the following cells, your environment is working fine!\n",
    "    - nbextensions will often display this message, but in reality everything is fine!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7807d6f2",
   "metadata": {},
   "source": [
    "## Shell/Terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c82413",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Which shell - mac users (zsh or bash?)\n",
    "shell = !echo $SHELL\n",
    "shell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67795f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo $PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd5defd",
   "metadata": {},
   "source": [
    "### Display the Profile For Your Terminal/GitBash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01955b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "!whoami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c56c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# ## Checking .bash_profile or .zshrc\n",
    "# if 'zsh' in shell[0]:\n",
    "#     print(f'[i] Using .zshrc')\n",
    "#     fname = r\"~/.zshrc\"\n",
    "# else:\n",
    "#     print(f'[i] Using .bash_profile')\n",
    "fname = r\"~/.bash_profile\"\n",
    "    \n",
    "profile = !cat {fname}\n",
    "print('\\n'.join(profile))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceea8363",
   "metadata": {},
   "source": [
    "# Package Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba26f7e0",
   "metadata": {},
   "source": [
    "## Pandas Profiling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7b68c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"https://docs.google.com/spreadsheets/d/e/2PACX-1vRsXeEswMPJqEh9xpXed0eJYaQf_aKkNCypU4TKvGrS_hucLW2IWUxrVBjlKQJR4Z_EQFE-YR4UUuTz/pub?output=csv\",\n",
    "                index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfb75da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "report = ProfileReport(df)\n",
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12cf9f6",
   "metadata": {},
   "source": [
    "## MODELING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0aab1e",
   "metadata": {},
   "source": [
    "### Scikit-learn v.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0918236f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector,make_column_transformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fb605d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ba6e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "## dropping column that are not helpful\n",
    "bad_cols = ['Name','Ticket']\n",
    "df.drop(columns=bad_cols,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e52019",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Specifying root names of types of features to loop through and filter out from df\n",
    "target_col = 'Survived'\n",
    "drop_cols = ['Cabin']\n",
    "\n",
    "y = df[target_col].copy()\n",
    "X = df.drop(columns=[target_col,*drop_cols]).copy()\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=321)\n",
    "y_train.value_counts(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c8c48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## feature selectors\n",
    "cat_sel = make_column_selector(dtype_include='object')\n",
    "num_sel = make_column_selector(dtype_include='number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe16c75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create pipelines and column transformer\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('imputer',SimpleImputer(strategy='median')),\n",
    "    ('scale',StandardScaler())])\n",
    "\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('imputer',SimpleImputer(strategy='constant',fill_value='MISSING')),\n",
    "    ('encoder',OneHotEncoder(sparse=False,handle_unknown='ignore',\n",
    "                             drop='first'))])\n",
    "                           \n",
    "                           \n",
    "                           \n",
    "## COMBINE BOTH PIPELINES INTO ONE WITH COLUMN TRANSFORMER\n",
    "preprocessor=ColumnTransformer(transformers=[\n",
    "    ('num',num_transformer,num_sel),\n",
    "    ('cat',cat_transformer,cat_sel)], verbose_feature_names_out=False)\n",
    "\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a1d2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit preprocessing pipeline on training data and pull out the feature names and X_cols\n",
    "preprocessor.fit(X_train)\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "## Transform X_traian,X_test and remake dfs\n",
    "X_train_df = pd.DataFrame(preprocessor.transform(X_train),\n",
    "                          index=X_train.index, columns=feature_names)\n",
    "X_test_df = pd.DataFrame(preprocessor.transform(X_test),\n",
    "                          index=X_test.index, columns=feature_names)\n",
    "X_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df67f2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification(model,X,y_true, classes=None, normalize='true',\n",
    "                            cmap=\"Blues\",  label=\"Test Data\", figsize=(5,3)): \n",
    "\n",
    "    ## Get Predictions\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    ## Classification Report / Scores \n",
    "    dashes = '---'*20\n",
    "    print(dashes)\n",
    "    print(f\"[i] CLASSIFICATION REPORT FOR: {label}\")\n",
    "    print(dashes)\n",
    "    \n",
    "    print(metrics.classification_report(y_true,y_pred,\n",
    "                                        target_names=classes))\n",
    "    # print(dashes)\n",
    "    \n",
    "\n",
    "    ## Plot a confusion matrix\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    metrics.ConfusionMatrixDisplay.from_predictions(y_true,y_pred,\n",
    "                                                         normalize=normalize,\n",
    "                                                        cmap=cmap,ax=ax)\n",
    "#     cm = metrics.confusion_matrix(y_true,y_pred,normalize=normalize,)\n",
    "#     # plt.figure(figsize=figsize)\n",
    "#     ax = sns.heatmap(cm, annot=True,square=True,cmap=cmap)\n",
    "\n",
    "    if classes != None:\n",
    "        ## Label classes\n",
    "        ax.set_xticklabels(classes)\n",
    "        ax.set_yticklabels(classes,rotation=0)\n",
    "\n",
    "    ## Add axis labels & title\n",
    "    ax.set_ylabel('True Classes')\n",
    "    ax.set_xlabel('Predicted Classes')\n",
    "    ax.set_title('Confusion Matrix');\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd6a0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_df,y_train)\n",
    "evaluate_classification(rf,X_test_df,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b7db28",
   "metadata": {},
   "source": [
    "## MODEL EXPLANATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f30dff",
   "metadata": {},
   "source": [
    "### Shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af4051a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap \n",
    "print(shap.__version__)\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ba24a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize an explainer with the model\n",
    "explainer = shap.TreeExplainer(rf)\n",
    "\n",
    "## Calculaate shap values for test data\n",
    "shap_values = explainer.shap_values(X_test_df,y_test)\n",
    "len(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5dfefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values[1],X_test_df,max_display=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563b10a9",
   "metadata": {},
   "source": [
    "### Lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cbe6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "lime_explainer =LimeTabularExplainer(\n",
    "    training_data=np.array(X_test_df),\n",
    "    feature_names=X_test_df.columns,\n",
    "    class_names=['Died', 'Survived'],\n",
    "    mode='classification'\n",
    ")\n",
    "\n",
    "row = np.random.choice(range(len(X_test_df)))\n",
    "target_lookup = {0:'Died',1:'Survived'}\n",
    "\n",
    "print(f\"- Row #: {row}\")\n",
    "print(f\"Class = {target_lookup[y_test.iloc[row]]}\")\n",
    "\n",
    "exp = lime_explainer.explain_instance(X_test_df.iloc[row], rf.predict_proba)\n",
    "exp.show_in_notebook(show_table=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18accc0",
   "metadata": {},
   "source": [
    "## ADVANCED MODELING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71dd82b",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df10da2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "clf = XGBClassifier()\n",
    "clf.fit(X_train_df, y_train)\n",
    "evaluate_classification(rf,X_test_df,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4838205f",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e836ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "clf = LGBMClassifier()\n",
    "clf.fit(X_train_df, y_train)\n",
    "evaluate_classification(rf,X_test_df,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0736b45",
   "metadata": {},
   "source": [
    "## Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec1b12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crime = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vQVbSOFab3WcS31FfOdDE7pYxSuo_O7epFxACZElgwUt1gId7qPtn7krQbp39NyAwoAtR7aTdYYtDOw/pub?output=csv',\n",
    "                parse_dates=['CrimeDateTime'],index_col=0)\n",
    "display(df_crime.head())\n",
    "df_crime.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07564cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pick a time series from above to work with\n",
    "ts = df_crime['LARCENY']\n",
    "ts.plot(figsize=(12,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01331e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = ts.resample('M').sum().loc[:\"2021\"]\n",
    "ts.plot(figsize=(12,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35023ced",
   "metadata": {},
   "source": [
    "### Statsmodels.tsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d9fbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.tsa.api as tsa\n",
    "## import seasonal_decompose\n",
    "decomp_mul = tsa.seasonal_decompose(ts,model='mul')#,model='mul')\n",
    "\n",
    "mpl.rcParams['figure.figsize']=(12,6)\n",
    "decomp_mul.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fb359e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train Test Split Index\n",
    "train_size = 0.8\n",
    "split_idx = round(len(ts)* train_size)\n",
    "split_idx\n",
    "\n",
    "## Split\n",
    "train = ts.iloc[:split_idx]\n",
    "test = ts.iloc[split_idx:]\n",
    "\n",
    "## Visualize split\n",
    "fig,ax= plt.subplots()\n",
    "kws = dict(ax=ax,marker='o')\n",
    "train.plot(**kws)\n",
    "test.plot(**kws)\n",
    "ax.legend(bbox_to_anchor=[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559d5c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.tsa.api as tsa\n",
    "d = 1\n",
    "p = 1\n",
    "q =1\n",
    "model = tsa.SARIMAX(train,order=(p,d,q),).fit()\n",
    "display(model.summary())\n",
    "model.plot_diagnostics();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66399c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "forecast = model.forecast(steps=len(test))\n",
    "forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba703f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting a forecast\n",
    "forecast = model.get_forecast(len(test))\n",
    "\n",
    "\n",
    "def forecast_to_df(forecast, name='forecast'):\n",
    "    test_pred = forecast.conf_int()\n",
    "    test_pred[name] = forecast.predicted_mean\n",
    "    test_pred.columns = ['lower','upper','prediction']\n",
    "    return test_pred\n",
    "\n",
    "\n",
    "pred_df = forecast_to_df(forecast)#,district)\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416feba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "train.plot(ax=ax,label='train')\n",
    "test.plot(ax=ax,label='test')\n",
    "\n",
    "pred_df['prediction'].plot(ax=ax,label='forecast',ls='--')\n",
    "\n",
    "ax.fill_between(x=pred_df.index,y1=pred_df['lower'],y2=pred_df['upper'])\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb95d68",
   "metadata": {},
   "source": [
    "## pmdarima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b2d4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pmdarima\n",
    "help(pmdarima.auto_arima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a40a61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_model = pmdarima.auto_arima(train,start_p=0,start_q=0)\n",
    "display(auto_model.summary())\n",
    "# help(auto_model\n",
    "auto_model.plot_diagnostics();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda607de",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mean,pred_conf_int = auto_model.predict(return_conf_int=True)\n",
    "pred_mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064ba81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({'pred':pred_mean, \n",
    "                        'conf_int_lower':pred_conf_int[:,0],\n",
    "                        'conf_int_upper':pred_conf_int[:,1]},\n",
    "                        index= pd.date_range(test.index[0],\n",
    "                                                  periods=10,freq='M'))\n",
    "# auto_model.conf_int()\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebbfe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tsa.SARIMAX(ts,order=auto_model.order,\n",
    "                     seasonal_order=auto_model.seasonal_order).fit()\n",
    "display(best_model.summary())\n",
    "best_model.plot_diagnostics();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44e11e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_test_pred(train,test,pred_df):\n",
    "    fig,ax = plt.subplots()\n",
    "    kws = dict(marker='o')\n",
    "    \n",
    "    ax.plot(train,label='Train',**kws)\n",
    "    ax.plot(test,label='Test',**kws)\n",
    "    ax.plot(pred_df['prediction'],label='prediction',ls='--',**kws)\n",
    "\n",
    "    ax.fill_between(x=pred_df.index,y1=pred_df['lower'],y2=pred_df['upper'])\n",
    "    ax.legend(bbox_to_anchor=[1,1])\n",
    "    fig.tight_layout()\n",
    "    return fig,ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341f7006",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = best_model.get_forecast(steps=12)#start=test.index[0],end=test.index[-1])\n",
    "pred_df = forecast_to_df(pred)\n",
    "display(plot_train_test_pred(train,test,pred_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a68502b",
   "metadata": {},
   "source": [
    "## Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c71a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "### COPIED FROM SOURCE: https://machinelearningmastery.com/time-series-forecasting-with-prophet-in-python/\n",
    "# make an in-sample forecast\n",
    "from pandas import read_csv\n",
    "from pandas import to_datetime\n",
    "from pandas import DataFrame\n",
    "from prophet import Prophet\n",
    "from matplotlib import pyplot\n",
    "# load data\n",
    "# path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/monthly-car-sales.csv'\n",
    "# df = read_csv(path, header=0)\n",
    "# df = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vQVbSOFab3WcS31FfOdDE7pYxSuo_O7epFxACZElgwUt1gId7qPtn7krQbp39NyAwoAtR7aTdYYtDOw/pub?output=csv',\n",
    "#                 parse_dates=['CrimeDateTime'],index_col=0)\n",
    "# display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f05319",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crime = df_crime.tz_convert(None)\n",
    "df_crime = df_crime.resample('M').sum()\n",
    "df_crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2c0e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = df_crime['LARCENY']\n",
    "ts_df = ts.reset_index()\n",
    "ts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40b776d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare expected column names\n",
    "ts_df.columns = ['ds', 'y']\n",
    "# ts_df['ds']= to_datetime(df['ds'])\n",
    "# define the model\n",
    "model = Prophet()\n",
    "# fit the model\n",
    "model.fit(ts_df)\n",
    "\n",
    "# define the period for which we want a prediction\n",
    "future = list()\n",
    "for i in range(1, 13):\n",
    "\tdate = '2022-%02d' % i\n",
    "\tfuture.append([date])\n",
    "    \n",
    "future = DataFrame(future)\n",
    "future.columns = ['ds']\n",
    "future['ds']= to_datetime(future['ds'])\n",
    "future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca698ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the model to make a forecast\n",
    "forecast = model.predict(future)\n",
    "# summarize the forecast\n",
    "print(forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].head())\n",
    "# plot forecast\n",
    "model.plot(forecast)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dbce09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_components(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2c1d70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55845c26",
   "metadata": {},
   "source": [
    "## sktime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8701a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sktime.utils.plotting import plot_series\n",
    "# from sktime.forecasting.base import ForecastingHorizon, ThetaForecaster\n",
    "# # from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "\n",
    "# # y_train, y_test = temporal_train_test_split(ts)\n",
    "\n",
    "# fh = ForecastingHorizon(test.index, is_relative=False)\n",
    "# forecaster = ThetaForecaster(sp=12)  # monthly seasonal periodicity\n",
    "# forecaster.fit(train)\n",
    "# y_pred = forecaster.predict(fh)\n",
    "# smape_loss(test, y_pred) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39b0962",
   "metadata": {},
   "source": [
    "## Pandas DataReader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b8545b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_datareader as pdr\n",
    "example = pdr.DataReader('GOOGL','yahoo','2012','2020')\n",
    "example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3f2253",
   "metadata": {},
   "source": [
    "# Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a2ac01",
   "metadata": {},
   "source": [
    "## Plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fe4c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "px.line(data_frame=df_crime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab7303d",
   "metadata": {},
   "source": [
    "## Sklearn `plot_tree`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56befdbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "tree = rf.estimators_[0]\n",
    "plot_tree(tree);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149d3b9a",
   "metadata": {},
   "source": [
    "## Yellowbrick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815162b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.datasets import load_credit\n",
    "from yellowbrick.features import Rank2D\n",
    "\n",
    "# Load the credit dataset\n",
    "X, y = load_credit()\n",
    "\n",
    "# Instantiate the visualizer with the Pearson ranking algorithm\n",
    "visualizer = Rank2D(algorithm='pearson')\n",
    "\n",
    "visualizer.fit(X, y)           # Fit the data to the visualizer\n",
    "visualizer.transform(X)        # Transform the data\n",
    "visualizer.show()              # Finalize and render the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593bc419",
   "metadata": {},
   "source": [
    "# Final Confirmation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a4c97a",
   "metadata": {},
   "source": [
    "- You should see the success message printed below the last code cell. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e0f5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"[i] SUCCESS. YOUR ENVIRONMENT IS FULLY FUNCTIONAL AND READY TO USE!\")\n",
    "end = dt.datetime.now(get_localzone())\n",
    "end_nice = end.strftime(\"%m/%d/%Y @ %I:%M:%S %p \") + f\"(tz={get_localzone_name().split('/')[-1]})\"\n",
    "print(f'    - Time Completed: {end_nice}')\n",
    "\n",
    "duration = end-now\n",
    "print(f'    - Total Time = {(end-now) } (\"HH:MM:SS.ms\")')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4de360",
   "metadata": {},
   "source": [
    "- If the message did not print, your notebook ran into an error somewhere above. \n",
    "\t- Scroll up to find the last cell that ran.\n",
    "\t- If an error message is displayed, follow the steps below to save a copy of the notebook to send to an instructor for help.\n",
    "\n",
    "### Files to Share for Troubleshooting\n",
    "\n",
    "- There are 2 files that you should share with your instructor/TA\n",
    "\t1. A copy of your Environment Tester notebook that error'd.\n",
    "\t2. A copy of \"FINAL_REPORT.txt\" file that is in the Troubleshooting folder of the repo.\n",
    "\t\n",
    "1. To share your notebook with an instructor/TA for help:\n",
    "\t- Click File > Save & Checkpoint.\n",
    "\t- Click File > Download As > Notebook (.ipynb)\n",
    "\t- You web browser should save a copy of the notebook to your normal \"Downloads\" folder.\n",
    "    \n",
    "<img src=\"images/download_as.png\" width=600px>\n",
    "\n",
    "2. To share a copy of your FINAL_REPORT.txt:\n",
    "\t- In the first Files tab that opened when you started jupyter notebook you should see a folder called \"Troubleshooting\"\n",
    "\t- Click on the troublshooting folder. \n",
    "\t- Inside the folder you should have a file called \"FINAL_REPORT.txt\".\n",
    "\t- Check the checkbox next to the file and the click on the \"Download\" button that appears at the top of the list of files.\n",
    "\t- Your web browser will also save this file to your Downloads folder.\n",
    "    \n",
    "<img src=\"images/download_report.png\" width=600px>\n",
    "\n",
    "- **Send an email to your instructor and cc: jirving@codingdojo.com**\n",
    "\t- Attach the 2 files listed above.\n",
    "\t- Add any additional details or info you think may be helpful for us to know.\n",
    "\t\t- For example:\n",
    "\t\t\t- \"my computer is really old and I think that may be part of the problem.\"\n",
    "\t\t\t- \"I share this computer with someone else who also uses python\"\n",
    "\t\n",
    "- An instructor or TA will get back to you within 1 business day with the next steps for you to try.\n",
    "\t- You will most likely need to set up a Zoom call and share your screen for us to help.\n",
    "\t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
